### 特征分箱的方法

[转自](https://blog.csdn.net/u013421629/article/details/78416748)

在建模中，需要对连续变量离散化，特征离散后，模型会更稳定，降低了模型过拟合的风险。

#### *有监督*的卡方分箱法（ChiMerge）

自底向上的（基于合并的）数据离散化方法

依赖于卡方检验：具有最小卡方值的相邻区间合并在一起，知道满足稳定的停止标准

#### 基本思想：

对于精确的离散化，相对类频率在一个区间内应当完全一致。因此，如果两个相邻的区间具有非常类似的类分布，则这两个区间可以合并；否则，应当保持分开。而低卡方值表明它们具有相似的类分布。



0. 预先设定一个卡方的阈值
1. 初始化：根据要离散的属性对实例进行排序，每个实例属于一个区间
2. 合并区间：
   - 计算每一对相邻区间的卡方值
   - 将卡方值最小的一对区间合并$X^2=\sum^{2}_{i=1}\sum^{2}_{j=1}\frac{(A_{ij}-E_{ij})^2}{E_{ij}}$
   - $A_{ij}$：第i区间第j类的实例的数量
   - $E_{ij}$：$A_{ij}$的期望频率=$\frac{N_i*C_j}{N}$，$N_i$是第i组的样本数，$C_j$是第j类样本在全体中的比例

这里需要注意初始化时需要对实例进行排序，在排序的基础上进行合并



#### 卡方值的确定：

根据显著性水平和自由度得到卡方值；自由度比类别数量小1

e.g.有3类，自由度为2，则90%置信度（10%显著性水平）下，卡方的值为4.6

#### 阈值的意义

类别和属性独立时，有90%的可能性，计算得到的卡方值会小于4.6。大于阈值4.6的卡方值就说明属性和类不是相互独立的，不能合并。如果阈值选的大，区间合并就会进行很多次，离散后的区间数量少。

#### 注：

1. ChiMerge算法推荐使用0.90、0.95、0.99置信度，最大区间数取10到15之间
2. 也可以不考虑卡方阈值，此时可以考虑最小区间数或者最大区间数。指定区间数量的上限和下限，最多几个区间，最少几个区间
3. 对于类别型变量，需要分箱时按照某种方式进行排序



#### *无监督*分箱法：等距划分、等频划分

#### 等距分箱

从最小值到最大值之间，均分为N等份，这样如果A、B为最小最大值，则每个区间的长度为$W=\frac{B-A}{N}$，则区间边界值为A+W，A+2W，...，A+(N-1)W。这里只考虑边界，每个等份里面的实例数量可能不等。

#### 等频分箱

区间的边界值要经过选择，使得每个区间包含大致相等的实例数量。比如说N=10，每个区间应该包含大约10%的实例。



#### 以上两种算法的弊端

等宽区间划分：划分为5区间，最高工资为50000，则所有工资低于10000的人都被划分到同一区间

等频区间划分：可能正好相反，所有工资高于50000的人都会被划分到50000这一区间中

这两种算法都忽略了实例所属的类型，落在正确区间里的偶然性很大。

